{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:rds_env]",
      "language": "python",
      "name": "conda-env-rds_env-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Fairness while Training Models",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DKrcGGhQild"
      },
      "source": [
        "# Lab 3: Exploring Fairness When Training Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SyL9goGBjya"
      },
      "source": [
        "In this lab, we will detect bias that may be introduced while training classifiers. We will mitigate this bias via pre-processing and post-processing.  \n",
        "\n",
        "This notebook has four stages in which we will: \n",
        "1. Import and split the data into train/val/test sets.\n",
        "2. Train a classifier to predict credit using original data with or without sensitive features.\n",
        "3. Preprocess the data using the reweighting algorithm and train a classifier using the reweighted data.\n",
        "4. Post-process the predictions using the calibrated equality of odds algorithm. For each prediction from step 2, 3, and 4, we will measure bias using fairness metrics including mean outcomes, disparate impact, false positive rate, and false negative rate. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKooNAay1wNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbafe8f3-d97d-4cd0-fec9-84a3980d3c7a"
      },
      "source": [
        "!pip install numba==0.48\n",
        "!pip install aif360==0.2.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numba==0.48\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/7f/dbe85f5f419dca88509d829df90dfa5aefa39c39f6b7020dfc206a386279/numba-0.48.0-1-cp36-cp36m-manylinux2014_x86_64.whl (3.5MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5MB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from numba==0.48) (1.19.5)\n",
            "Collecting llvmlite<0.32.0,>=0.31.0dev0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/bb/60d4033d56c9da36490af19caa6c794b72b8aef6f792fdfa8cb95d11e419/llvmlite-0.31.0-cp36-cp36m-manylinux1_x86_64.whl (20.2MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 41.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba==0.48) (53.0.0)\n",
            "\u001b[31mERROR: umap-learn 0.5.0 has requirement numba>=0.49, but you'll have numba 0.48.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pynndescent 0.5.1 has requirement numba>=0.51.2, but you'll have numba 0.48.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: llvmlite, numba\n",
            "  Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed llvmlite-0.31.0 numba-0.48.0\n",
            "Collecting aif360==0.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/54/09e0674fc1370072385d64e0282eff0857e3d78c3abd7d6471200cf7a00d/aif360-0.2.2-py2.py3-none-any.whl (56.4MB)\n",
            "\u001b[K     |████████████████████████████████| 56.4MB 68kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from aif360==0.2.2) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.23.3 in /usr/local/lib/python3.6/dist-packages (from aif360==0.2.2) (1.1.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from aif360==0.2.2) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from aif360==0.2.2) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->aif360==0.2.2) (1.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.3->aif360==0.2.2) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.3->aif360==0.2.2) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.3->aif360==0.2.2) (1.15.0)\n",
            "Installing collected packages: aif360\n",
            "Successfully installed aif360-0.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyPDr4QuQilp"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "\n",
        "import random\n",
        "random.seed(6)\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "from aif360.algorithms.preprocessing import Reweighing\n",
        "from aif360.datasets import GermanDataset, StandardDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
        "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY7AwOvjQilr"
      },
      "source": [
        "## Step 1: Load the data\n",
        "\n",
        "The German Credit Risk dataset contains 1000 entries with 20 categorial/symbolic attributes prepared by Prof. Hofmann. In this dataset, each entry represents a person who takes a credit by a bank. Each person is classified as good or bad credit risks according to the set of attributes. The original dataset can be found at https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvvwkowuQilr"
      },
      "source": [
        "### 1.1 Read in the aif360 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW9hntAiQils"
      },
      "source": [
        "dataset_orig = GermanDataset(protected_attribute_names=['age'],           \n",
        "                             privileged_classes=[lambda x: x >= 25], \n",
        "                             features_to_drop=['personal_status', 'sex'])      # age >=25 is considered privileged\n",
        "\n",
        "# Store definitions of priviledged and unpriviledged groups\n",
        "privileged_groups = [{'age': 1}]\n",
        "unprivileged_groups = [{'age': 0}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eYd60CSQilt"
      },
      "source": [
        "### 1.2 Split into train/val/test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hNDW2gWQilu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c1d2b4c-3f96-4b4f-e479-2d64a26697db"
      },
      "source": [
        "# Split original data into train and test data\n",
        "train_orig, test_orig = dataset_orig.split([0.8], shuffle=True, seed=10)\n",
        "# Split training data in to training and validation data for hyperparameter tuning\n",
        "train_orig, val_orig = train_orig.split([0.75], shuffle=True)\n",
        "\n",
        "# Convert to dataframes\n",
        "train_orig_df, _ = train_orig.convert_to_dataframe()\n",
        "val_orig_df, _ = val_orig.convert_to_dataframe()\n",
        "test_orig_df, _ = test_orig.convert_to_dataframe()\n",
        "\n",
        "print(\"Train set: \", train_orig_df.shape)\n",
        "print(\"Val set: \", val_orig_df.shape)\n",
        "print(\"Test set: \", test_orig_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set:  (600, 58)\n",
            "Val set:  (200, 58)\n",
            "Test set:  (200, 58)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y1Ubj8DQilw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "342d6378-91ee-4509-9037-5dff55d09e5c"
      },
      "source": [
        "print(train_orig_df.columns)\n",
        "train_orig_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['month', 'credit_amount', 'investment_as_income_percentage',\n",
            "       'residence_since', 'age', 'number_of_credits', 'people_liable_for',\n",
            "       'status=A11', 'status=A12', 'status=A13', 'status=A14',\n",
            "       'credit_history=A30', 'credit_history=A31', 'credit_history=A32',\n",
            "       'credit_history=A33', 'credit_history=A34', 'purpose=A40',\n",
            "       'purpose=A41', 'purpose=A410', 'purpose=A42', 'purpose=A43',\n",
            "       'purpose=A44', 'purpose=A45', 'purpose=A46', 'purpose=A48',\n",
            "       'purpose=A49', 'savings=A61', 'savings=A62', 'savings=A63',\n",
            "       'savings=A64', 'savings=A65', 'employment=A71', 'employment=A72',\n",
            "       'employment=A73', 'employment=A74', 'employment=A75',\n",
            "       'other_debtors=A101', 'other_debtors=A102', 'other_debtors=A103',\n",
            "       'property=A121', 'property=A122', 'property=A123', 'property=A124',\n",
            "       'installment_plans=A141', 'installment_plans=A142',\n",
            "       'installment_plans=A143', 'housing=A151', 'housing=A152',\n",
            "       'housing=A153', 'skill_level=A171', 'skill_level=A172',\n",
            "       'skill_level=A173', 'skill_level=A174', 'telephone=A191',\n",
            "       'telephone=A192', 'foreign_worker=A201', 'foreign_worker=A202',\n",
            "       'credit'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>credit_amount</th>\n",
              "      <th>investment_as_income_percentage</th>\n",
              "      <th>residence_since</th>\n",
              "      <th>age</th>\n",
              "      <th>number_of_credits</th>\n",
              "      <th>people_liable_for</th>\n",
              "      <th>status=A11</th>\n",
              "      <th>status=A12</th>\n",
              "      <th>status=A13</th>\n",
              "      <th>status=A14</th>\n",
              "      <th>credit_history=A30</th>\n",
              "      <th>credit_history=A31</th>\n",
              "      <th>credit_history=A32</th>\n",
              "      <th>credit_history=A33</th>\n",
              "      <th>credit_history=A34</th>\n",
              "      <th>purpose=A40</th>\n",
              "      <th>purpose=A41</th>\n",
              "      <th>purpose=A410</th>\n",
              "      <th>purpose=A42</th>\n",
              "      <th>purpose=A43</th>\n",
              "      <th>purpose=A44</th>\n",
              "      <th>purpose=A45</th>\n",
              "      <th>purpose=A46</th>\n",
              "      <th>purpose=A48</th>\n",
              "      <th>purpose=A49</th>\n",
              "      <th>savings=A61</th>\n",
              "      <th>savings=A62</th>\n",
              "      <th>savings=A63</th>\n",
              "      <th>savings=A64</th>\n",
              "      <th>savings=A65</th>\n",
              "      <th>employment=A71</th>\n",
              "      <th>employment=A72</th>\n",
              "      <th>employment=A73</th>\n",
              "      <th>employment=A74</th>\n",
              "      <th>employment=A75</th>\n",
              "      <th>other_debtors=A101</th>\n",
              "      <th>other_debtors=A102</th>\n",
              "      <th>other_debtors=A103</th>\n",
              "      <th>property=A121</th>\n",
              "      <th>property=A122</th>\n",
              "      <th>property=A123</th>\n",
              "      <th>property=A124</th>\n",
              "      <th>installment_plans=A141</th>\n",
              "      <th>installment_plans=A142</th>\n",
              "      <th>installment_plans=A143</th>\n",
              "      <th>housing=A151</th>\n",
              "      <th>housing=A152</th>\n",
              "      <th>housing=A153</th>\n",
              "      <th>skill_level=A171</th>\n",
              "      <th>skill_level=A172</th>\n",
              "      <th>skill_level=A173</th>\n",
              "      <th>skill_level=A174</th>\n",
              "      <th>telephone=A191</th>\n",
              "      <th>telephone=A192</th>\n",
              "      <th>foreign_worker=A201</th>\n",
              "      <th>foreign_worker=A202</th>\n",
              "      <th>credit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>822</th>\n",
              "      <td>36.0</td>\n",
              "      <td>2712.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830</th>\n",
              "      <td>24.0</td>\n",
              "      <td>2375.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>703</th>\n",
              "      <td>30.0</td>\n",
              "      <td>2503.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>776</th>\n",
              "      <td>36.0</td>\n",
              "      <td>3535.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>659</th>\n",
              "      <td>18.0</td>\n",
              "      <td>6361.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     month  credit_amount  ...  foreign_worker=A202  credit\n",
              "822   36.0         2712.0  ...                  0.0     2.0\n",
              "830   24.0         2375.0  ...                  0.0     1.0\n",
              "703   30.0         2503.0  ...                  0.0     1.0\n",
              "776   36.0         3535.0  ...                  0.0     1.0\n",
              "659   18.0         6361.0  ...                  0.0     1.0\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9G0RdfbQilw"
      },
      "source": [
        "As a reminder of what we did last week, let's calculate some fairness metrics on the training data (hint, use `BinarylabelDatasetMetric`):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoazzmDQQilx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb3b2dd1-d0e3-4985-8762-e22465208003"
      },
      "source": [
        "# write your code here\n",
        "metric_train_orig = BinaryLabelDatasetMetric(\n",
        "     train_orig, \n",
        "     unprivileged_groups = unprivileged_groups,\n",
        "     privileged_groups = privileged_groups\n",
        "  )\n",
        "print(\"Original training dataset\")\n",
        "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_train_orig.mean_difference())\n",
        "print(\"Disparate Impact = %f\" % metric_train_orig.disparate_impact())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original training dataset\n",
            "Difference in mean outcomes between unprivileged and privileged groups = -0.135481\n",
            "Disparate Impact = 0.814721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vXjQtpLQily"
      },
      "source": [
        "## Step 2: Train a classifier to predict credit using the original data\n",
        "\n",
        "We will be training a logistic regression model to predict good/bad credit, then fine-tuning the model over a set of hyperparameters. Then, we'll see how well this basic model does on some fairness metrics. \n",
        "\n",
        "### 2.1 Training and evaluating a logistic regression model \n",
        "First, we need to split our data up into the explantory variables (x) and the outcome variable (y). We will recode the outcome so that the values are 0 (= bad credit) and 1 (= good credit). This is the format that the sklearn logistic regression function expects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq3P6dXAQilz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eab3d0be-d19f-4380-c9b4-a5e77304603c"
      },
      "source": [
        "x_train = train_orig_df.drop(\"credit\", axis=1)\n",
        "y_train = train_orig_df.credit.replace({2:0}) \n",
        "print(\"Outcomes: \")\n",
        "y_train.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Outcomes: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    426\n",
              "0.0    174\n",
              "Name: credit, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI8BpcTIQil0"
      },
      "source": [
        "Next, we can fit our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHtshyRkQil1"
      },
      "source": [
        "# Set up the logistic regression model with the given hyperparameters\n",
        "initial_lr = LogisticRegression(C=0.5, penalty=\"l1\", solver='liblinear')\n",
        "    \n",
        "# Fit the model using the training data\n",
        "initial_lr = initial_lr.fit(x_train, y_train, sample_weight=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QKB7FaGQil2"
      },
      "source": [
        "Now that we have a trained model, we should evaluate it on our validation set. For now, we'll look the AUC as well as accuracy when we use a cutoff of 0.5 (that is, predicted values over 0.5 are interpreted as good credit, and vice versa).\n",
        "\n",
        "Let's write a funciton to do that, too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA-5D7WYQil2"
      },
      "source": [
        "def evaluate(model, X, y_true):\n",
        "    '''Calculates the AUC and accuracy for a trained logistic regression model'''\n",
        "    \n",
        "    # Calculate predicted values\n",
        "    y_pred = model.predict_proba(X)\n",
        "    # This returns a tuple for each observation containing the probability of being in each class.\n",
        "    # Since we're doing binary classification, all we need to know is the probability that the outcome = 1 (good credit)\n",
        "    y_pred = [row[1] for row in y_pred] # This pulls the predicted probability that y = 1 for each observation\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_true, [pred_prob >= 0.5 for pred_prob in y_pred])\n",
        "    \n",
        "    # Calculate AUC\n",
        "    auc = roc_auc_score(y_true, y_pred)\n",
        "    \n",
        "    return accuracy, auc\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv-4T2iiQil3"
      },
      "source": [
        "# Before we call the function, we need to set up the validation data properly, the way we did for the training data.\n",
        "x_val = val_orig_df.drop(\"credit\", axis=1)\n",
        "y_val = val_orig_df.credit.replace({2:0}) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc52k1sgQil4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b71d4d98-0829-45fb-d6c4-bb3a820f51f4"
      },
      "source": [
        "accuracy, auc = evaluate(initial_lr, x_val, y_val)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"AUC: \", auc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.72\n",
            "AUC:  0.784644415615049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-PyJ6fdQil4"
      },
      "source": [
        "### 2.2 Hyperparameter tuning the logistic regression model \n",
        "\n",
        "For hyperparameter tuning, we want to be able to easily train models with a variety of hyperparameter and determine which one performs the best on the validation data. We can use the functions we wrote above to do this. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJucCUYUQil5"
      },
      "source": [
        "def tune_logistic_regression(train_df, val_df, penalty_types, C_values, weights=None, verbose=True):\n",
        "    '''Tunes logistic regression models over the hyperparameters penalty type and C\n",
        "       to maximize the AUC'''\n",
        "    # Pre-process the training and validation data\n",
        "    x_train = train_df.drop(\"credit\", axis=1)\n",
        "    y_train = train_df.credit.replace({2:0}) \n",
        "    x_val = val_df.drop(\"credit\", axis=1)\n",
        "    y_val = val_df.credit.replace({2:0}) \n",
        "\n",
        "    # Create empty lists where we will store the results of hyperparameter tuning \n",
        "    parameters = []\n",
        "    models = []\n",
        "    val_aucs = []\n",
        "    \n",
        "    # Loop through the hyperparameters of interest\n",
        "    for penalty in penalty_types:\n",
        "        for C in C_values:\n",
        "            \n",
        "            # Train the logistic regression model with the given hyperparameters\n",
        "            lr = LogisticRegression(C=C, penalty=penalty, solver='liblinear')\n",
        "    \n",
        "            # Fit the model using the training data\n",
        "            lr = lr.fit(x_train, y_train, sample_weight=weights)\n",
        "            \n",
        "            # Get the evalution metrics on the validation set \n",
        "            accuracy, auc  = evaluate(lr, x_val, y_val)\n",
        "            \n",
        "            # Store the results\n",
        "            parameters.append({'penalty': penalty, 'C': C})\n",
        "            models.append(lr)\n",
        "            val_aucs.append(auc)\n",
        "            \n",
        "            # Print the results\n",
        "            if verbose:\n",
        "                print(\"\\nParmeters: \\tpenalty={} \\tC={}\".format(penalty, C))\n",
        "                print(\"Validtion AUC: {}\".format(auc))\n",
        "            \n",
        "    \n",
        "    # Determine the best model -- that is, the one with the AUC\n",
        "    best_model_index = np.argmax(val_aucs)\n",
        "    best_model = models[best_model_index]\n",
        "    \n",
        "    print(\"\\nBest model parameters: \", parameters[best_model_index])\n",
        "    print(\"Best model AUC: \", val_aucs[best_model_index])\n",
        "    \n",
        "    # Return best model\n",
        "    return best_model, parameters, models, val_aucs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZDRZopwQil6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "395b6d8f-64bf-41ae-f996-2cecc7f71255"
      },
      "source": [
        "best_lr, parameters, models, val_aucs = tune_logistic_regression(train_orig_df, val_orig_df, penalty_types=[\"l1\", \"l2\"], C_values=[0.001, 0.1, 1, 10, 100, 1000, 10000, 100000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Parmeters: \tpenalty=l1 \tC=0.001\n",
            "Validtion AUC: 0.4036442976766128\n",
            "\n",
            "Parmeters: \tpenalty=l1 \tC=0.1\n",
            "Validtion AUC: 0.7456067932539214\n",
            "\n",
            "Parmeters: \tpenalty=l1 \tC=1\n",
            "Validtion AUC: 0.7720250029484608\n",
            "\n",
            "Parmeters: \tpenalty=l1 \tC=10\n",
            "Validtion AUC: 0.745135039509376\n",
            "\n",
            "Parmeters: \tpenalty=l1 \tC=100\n",
            "Validtion AUC: 0.7411251326807405\n",
            "\n",
            "Parmeters: \tpenalty=l1 \tC=1000\n",
            "Validtion AUC: 0.741243071116877\n",
            "\n",
            "Parmeters: \tpenalty=l1 \tC=10000\n",
            "Validtion AUC: 0.7411251326807408\n",
            "\n",
            "Parmeters: \tpenalty=l1 \tC=100000\n",
            "Validtion AUC: 0.7424224554782403\n",
            "\n",
            "Parmeters: \tpenalty=l2 \tC=0.001\n",
            "Validtion AUC: 0.6545583205566695\n",
            "\n",
            "Parmeters: \tpenalty=l2 \tC=0.1\n",
            "Validtion AUC: 0.7965561976648191\n",
            "\n",
            "Parmeters: \tpenalty=l2 \tC=1\n",
            "Validtion AUC: 0.7690765420450525\n",
            "\n",
            "Parmeters: \tpenalty=l2 \tC=10\n",
            "Validtion AUC: 0.7648307583441443\n",
            "\n",
            "Parmeters: \tpenalty=l2 \tC=100\n",
            "Validtion AUC: 0.7653025120886896\n",
            "\n",
            "Parmeters: \tpenalty=l2 \tC=1000\n",
            "Validtion AUC: 0.7668357117584621\n",
            "\n",
            "Parmeters: \tpenalty=l2 \tC=10000\n",
            "Validtion AUC: 0.7648307583441444\n",
            "\n",
            "Parmeters: \tpenalty=l2 \tC=100000\n",
            "Validtion AUC: 0.7676612808114164\n",
            "\n",
            "Best model parameters:  {'penalty': 'l2', 'C': 0.1}\n",
            "Best model AUC:  0.7965561976648191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j05GktrQil7"
      },
      "source": [
        "Let's plot the results so that we understand what hyperparameter tuning actually did."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz0veGCfQil7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "58cd707d-6c5c-49b7-aed3-d61e4e7e7a4d"
      },
      "source": [
        "val_aucs_l1 = [val_aucs[i] for i in range(len(val_aucs)) if parameters[i]['penalty']==\"l1\"]\n",
        "val_aucs_l2 = [val_aucs[i] for i in range(len(val_aucs)) if parameters[i]['penalty']==\"l2\"]\n",
        "C_values = [parameters[i]['C'] for i in range(len(parameters)) if parameters[i]['penalty']==\"l2\"]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.semilogx( C_values, val_aucs_l1, marker='.', markerfacecolor='blue', markersize=12, color='blue', linewidth=4, label='L1 Penalty')\n",
        "ax.semilogx( C_values, val_aucs_l2, marker='.', markerfacecolor='red', markersize=12, color='red', linewidth=4, label='L2 Penalty')\n",
        "ax.set_xlabel(\"C\")\n",
        "ax.set_ylabel(\"AUC\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mzab0o-5Qil8"
      },
      "source": [
        "### 2.3 Evaluating bias in our predictions\n",
        "\n",
        "Let's put our data back into a aif360 dataset format, so that we can use all of the fairness metrics provided by the package. For now, we'll evaluate bias on the training data. This mimics the development process we'd use in any real application.\n",
        "\n",
        "First, we'll get predicted values using the best model and attach them as a new column in the data frame. We'll use 0.5 as the threshold as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xhb_wlGQil8"
      },
      "source": [
        "# Copy the dataset\n",
        "train_preds_df = train_orig_df.copy()\n",
        "# Calculate predicted values\n",
        "train_preds_df['credit'] = best_lr.predict(x_train)\n",
        "# Recode the predictions so that they match the format that the dataset was originally provided in \n",
        "# (1 = good credit, 2 = bad credit)\n",
        "train_preds_df['credit'] = train_preds_df.credit.replace({0:2})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-PK4GJ-Qil9"
      },
      "source": [
        "Then we'll create an object of the aif360 StandardDataset class. You can read more about this in the documentation:\n",
        "https://aif360.readthedocs.io/en/latest/modules/standard_datasets.html#aif360.datasets.StandardDataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5rMozURQil-"
      },
      "source": [
        "orig_aif360 = StandardDataset(train_orig_df, label_name='credit', protected_attribute_names=['age'], \n",
        "                privileged_classes=[[1]], favorable_classes=[1])\n",
        "preds_aif360 = StandardDataset(train_preds_df, label_name='credit', protected_attribute_names=['age'], \n",
        "                privileged_classes=[[1]], favorable_classes=[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QclM1irQQil_"
      },
      "source": [
        "Now, let's calculate some fairness metrics!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLv4s4agQimA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70f4e1e2-25fa-4eca-8850-dee37ce33bd2"
      },
      "source": [
        "# write your code here\n",
        "metric_train_orig = BinaryLabelDatasetMetric(\n",
        "     orig_aif360, \n",
        "     unprivileged_groups = unprivileged_groups,\n",
        "     privileged_groups = privileged_groups\n",
        "  )\n",
        "print(\"Original training dataset\")\n",
        "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_train_orig.mean_difference())\n",
        "print(\"Disparate Impact = %f\" % metric_train_orig.disparate_impact())\n",
        "\n",
        "metric_train_preds = BinaryLabelDatasetMetric(\n",
        "     preds_aif360, \n",
        "     unprivileged_groups = unprivileged_groups,\n",
        "     privileged_groups = privileged_groups\n",
        "  )\n",
        "print(\"\\nPrediction training dataset\")\n",
        "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_train_preds.mean_difference())\n",
        "print(\"Disparate Impact = %f\" % metric_train_preds.disparate_impact())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original training dataset\n",
            "Difference in mean outcomes between unprivileged and privileged groups = -0.135481\n",
            "Disparate Impact = 0.814721\n",
            "\n",
            "Prediction training dataset\n",
            "Difference in mean outcomes between unprivileged and privileged groups = -0.221386\n",
            "Disparate Impact = 0.742480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7df8vbdGQimC"
      },
      "source": [
        "Recall from last week that we identified bias in the training data. We should therefore not find it surprising that we have bias in a model trained on that data.\n",
        "\n",
        "Now, since we have true values and predicted values, let's compare the true positive rate and false positive rate by group. This is similar to the analysis ProPublica did. \n",
        "\n",
        "Note that aif360 is pretty picky about what goes into this ClassificationMetric class, which is the reason for all the inefficient copying of datasets above. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcQplgqVQimD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf1e6c13-3861-4a67-f069-88836965da21"
      },
      "source": [
        "orig_vs_preds_metrics = ClassificationMetric(orig_aif360, preds_aif360,\n",
        "                                                   unprivileged_groups=unprivileged_groups,\n",
        "                                                   privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"\\nError rate difference (unprivileged error rate - privileged error rate)= %f\" % orig_vs_preds_metrics.error_rate_difference())\n",
        "\n",
        "\n",
        "print(\"\\nFalse negative rate for privledged groups = %f\" % orig_vs_preds_metrics.false_negative_rate(privileged=True))\n",
        "print(\"False negative rate for unprivledged groups = %f\" % orig_vs_preds_metrics.false_negative_rate(privileged=False))\n",
        "print(\"False negative rate ratio = %f\" % orig_vs_preds_metrics.false_negative_rate_ratio())\n",
        "\n",
        "\n",
        "print(\"\\nFalse positive rate for privledged groups = %f\" % orig_vs_preds_metrics.false_positive_rate(privileged=True))\n",
        "print(\"False positive rate for unprivledged groups = %f\" % orig_vs_preds_metrics.false_positive_rate(privileged=False))\n",
        "print(\"False positive rate ratio = %f\" % orig_vs_preds_metrics.false_positive_rate_ratio())\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error rate difference (unprivileged error rate - privileged error rate)= 0.090362\n",
            "\n",
            "False negative rate for privledged groups = 0.054054\n",
            "False negative rate for unprivledged groups = 0.214286\n",
            "False negative rate ratio = 3.964286\n",
            "\n",
            "False positive rate for privledged groups = 0.625000\n",
            "False positive rate for unprivledged groups = 0.421053\n",
            "False positive rate ratio = 0.673684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpZ6MIDRQimE"
      },
      "source": [
        "This confirms it: our model is even *more* biased than the original credit scores.  \n",
        "\n",
        "Let's try to fix that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOv7pZhwQimF"
      },
      "source": [
        "## Step 3: Train a classifier to predict credit using the original data, excluding the sensitive feature\n",
        "\n",
        "We've talked several times in class about how removing a sensitive attribute is not enough. Let's see if that's true in action."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrCaX_SXQimG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a314da-e7b4-42e6-8a2e-03fc20e4dfa9"
      },
      "source": [
        "best_lr_noage, _, _, _ = tune_logistic_regression(train_orig_df.drop('age', axis=1), val_orig_df.drop('age', axis=1),\n",
        "                                                                       penalty_types=[\"l1\", \"l2\"], C_values=[0.001, 0.1, 1, 10, 100, 1000, 10000, 100000], verbose=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Best model parameters:  {'penalty': 'l2', 'C': 0.1}\n",
            "Best model AUC:  0.7816959547116406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcN-PxAcQimH"
      },
      "source": [
        "Note that the AUC of our best model is *slightly* worse than before: by excluding a feature, we've lost some predictive power."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koTe6gNlQimH"
      },
      "source": [
        "Now let's check the same bias metrics again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BedpLxvSQimH"
      },
      "source": [
        "preds_df_noage = train_orig_df.copy()\n",
        "preds_df_noage['credit'] = best_lr_noage.predict(x_train.drop('age', axis=1))\n",
        "preds_df_noage['credit'] = preds_df_noage.credit.replace({0:2})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O0TMLAmQimI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a299eb7-de94-4c93-eb0b-41415a0a5093"
      },
      "source": [
        "noage_preds_aif360 = StandardDataset(preds_df_noage, label_name='credit', protected_attribute_names=['age'], \n",
        "                privileged_classes=[[1]], favorable_classes=[1])\n",
        "\n",
        "\n",
        "noage_preds_metrics = BinaryLabelDatasetMetric(noage_preds_aif360, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "print(\"Mean difference = %f\" % noage_preds_metrics.mean_difference())\n",
        "print(\"Disparate Impact = %f\" % noage_preds_metrics.disparate_impact())\n",
        "\n",
        "orig_vs_noage_preds_metrics = ClassificationMetric(orig_aif360, noage_preds_aif360,\n",
        "                                                   unprivileged_groups=unprivileged_groups,\n",
        "                                                   privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"\\nError rate difference (unprivileged error rate - privileged error rate)= %f\" % orig_vs_noage_preds_metrics.error_rate_difference())\n",
        "\n",
        "\n",
        "print(\"\\nFalse negative rate for privledged groups = %f\" % orig_vs_noage_preds_metrics.false_negative_rate(privileged=True))\n",
        "print(\"False negative rate for unprivledged groups = %f\" % orig_vs_noage_preds_metrics.false_negative_rate(privileged=False))\n",
        "print(\"False negative rate ratio = %f\" % orig_vs_noage_preds_metrics.false_negative_rate_ratio())\n",
        "\n",
        "\n",
        "print(\"\\nFalse positive rate for privledged groups = %f\" % orig_vs_noage_preds_metrics.false_positive_rate(privileged=True))\n",
        "print(\"False positive rate for unprivledged groups = %f\" % orig_vs_noage_preds_metrics.false_positive_rate(privileged=False))\n",
        "print(\"False positive rate ratio = %f\" % orig_vs_noage_preds_metrics.false_positive_rate_ratio())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean difference = -0.156337\n",
            "Disparate Impact = 0.815603\n",
            "\n",
            "Error rate difference (unprivileged error rate - privileged error rate)= 0.079724\n",
            "\n",
            "False negative rate for privledged groups = 0.062162\n",
            "False negative rate for unprivledged groups = 0.160714\n",
            "False negative rate ratio = 2.585404\n",
            "\n",
            "False positive rate for privledged groups = 0.602941\n",
            "False positive rate for unprivledged groups = 0.473684\n",
            "False positive rate ratio = 0.785623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx5z3o5BQimI"
      },
      "source": [
        "Scroll up -- how do these numbers for our model that doesn't use age compare to the model that *does* use it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjBBTBfXDufF"
      },
      "source": [
        "**Write your comparison in this text cell:** The false negative rate ratio goes down, but the false positive rate ratio goes up indicating that there is less and more bias for the respective false negative and false positive rate ratio outcomes. There is also not much drastic change with the mean difference and disparate impact, indicating that filtering out age does not impact the bias of the prediction results of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAw3h8fUQimJ"
      },
      "source": [
        "## Step 4: Preprocess the data using the reweighting algorithm, then train a classifier to predict credit using the re-weighted data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APqjkl5aQimJ"
      },
      "source": [
        "# Fit the weights to our training data\n",
        "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
        "                privileged_groups=privileged_groups)\n",
        "RW_fit = RW.fit(train_orig)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziXVHt8uQimK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51257c9a-229e-4811-a27e-1ae149f6bd2c"
      },
      "source": [
        "# Pull the actual values of the weights for the training data\n",
        "train_reweighed = RW_fit.transform(train_orig)\n",
        "training_weights = train_reweighed.instance_weights\n",
        "training_weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.07897059, 0.97097297, 0.97097297, 0.97097297, 0.97097297,\n",
              "       0.71736842, 1.07897059, 0.97097297, 1.19178571, 0.97097297,\n",
              "       0.97097297, 0.71736842, 1.07897059, 0.97097297, 0.97097297,\n",
              "       0.97097297, 1.07897059, 0.97097297, 1.07897059, 0.97097297,\n",
              "       1.19178571, 0.97097297, 0.97097297, 1.07897059, 1.19178571,\n",
              "       0.71736842, 0.97097297, 1.19178571, 1.07897059, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.97097297, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.97097297, 1.07897059, 1.19178571,\n",
              "       0.97097297, 1.07897059, 0.97097297, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.97097297, 0.97097297, 1.07897059,\n",
              "       0.97097297, 0.97097297, 1.07897059, 0.97097297, 1.19178571,\n",
              "       0.97097297, 0.97097297, 1.19178571, 0.97097297, 0.97097297,\n",
              "       0.97097297, 1.19178571, 0.97097297, 1.07897059, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.71736842, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.97097297, 0.97097297, 1.19178571,\n",
              "       0.97097297, 0.97097297, 0.97097297, 0.97097297, 1.07897059,\n",
              "       0.97097297, 1.07897059, 0.71736842, 1.07897059, 0.97097297,\n",
              "       0.71736842, 1.07897059, 0.97097297, 1.07897059, 0.71736842,\n",
              "       0.97097297, 0.97097297, 1.19178571, 0.97097297, 1.19178571,\n",
              "       1.07897059, 1.07897059, 0.97097297, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.71736842, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 1.07897059, 0.97097297, 0.97097297,\n",
              "       1.19178571, 1.19178571, 1.07897059, 0.97097297, 1.07897059,\n",
              "       0.97097297, 0.97097297, 0.97097297, 0.97097297, 0.97097297,\n",
              "       1.07897059, 0.97097297, 0.97097297, 1.07897059, 0.71736842,\n",
              "       0.97097297, 0.97097297, 0.97097297, 1.07897059, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.97097297, 0.97097297, 1.07897059,\n",
              "       1.07897059, 0.71736842, 1.19178571, 1.07897059, 1.07897059,\n",
              "       1.19178571, 1.07897059, 1.07897059, 1.07897059, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.97097297, 1.07897059, 1.07897059,\n",
              "       0.97097297, 0.97097297, 1.07897059, 0.97097297, 0.97097297,\n",
              "       1.07897059, 0.97097297, 1.07897059, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 1.07897059, 1.19178571, 0.97097297,\n",
              "       0.71736842, 1.19178571, 0.71736842, 0.97097297, 1.07897059,\n",
              "       1.07897059, 1.07897059, 0.97097297, 1.07897059, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.97097297, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.97097297, 0.97097297, 0.71736842,\n",
              "       0.97097297, 0.97097297, 1.07897059, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.71736842, 1.07897059, 0.97097297, 0.97097297,\n",
              "       1.07897059, 1.07897059, 0.97097297, 0.97097297, 1.07897059,\n",
              "       1.07897059, 0.97097297, 1.19178571, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.71736842, 1.19178571, 0.97097297,\n",
              "       0.97097297, 1.07897059, 1.07897059, 1.19178571, 1.07897059,\n",
              "       0.97097297, 1.07897059, 0.97097297, 1.19178571, 0.97097297,\n",
              "       1.07897059, 0.97097297, 1.07897059, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.71736842, 1.07897059, 0.97097297, 0.97097297,\n",
              "       0.97097297, 1.07897059, 0.97097297, 0.97097297, 1.07897059,\n",
              "       1.07897059, 0.97097297, 1.19178571, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.97097297, 0.97097297, 0.97097297,\n",
              "       1.07897059, 0.97097297, 0.97097297, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 1.07897059, 0.97097297, 0.97097297,\n",
              "       0.71736842, 0.97097297, 0.97097297, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.97097297, 0.71736842, 0.71736842,\n",
              "       1.07897059, 0.97097297, 1.07897059, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.97097297, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.97097297, 0.97097297, 1.07897059,\n",
              "       1.07897059, 1.07897059, 0.97097297, 0.97097297, 0.97097297,\n",
              "       0.97097297, 1.07897059, 0.97097297, 0.97097297, 0.97097297,\n",
              "       1.07897059, 0.71736842, 0.97097297, 1.19178571, 0.97097297,\n",
              "       1.07897059, 0.97097297, 0.97097297, 0.97097297, 1.19178571,\n",
              "       0.71736842, 0.97097297, 1.07897059, 1.07897059, 1.19178571,\n",
              "       0.97097297, 0.97097297, 0.97097297, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.71736842, 0.97097297, 0.97097297, 0.97097297,\n",
              "       1.07897059, 0.97097297, 0.97097297, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.97097297, 1.07897059, 0.97097297,\n",
              "       1.19178571, 0.97097297, 0.97097297, 0.97097297, 0.97097297,\n",
              "       1.07897059, 0.97097297, 0.97097297, 0.97097297, 0.97097297,\n",
              "       0.97097297, 1.07897059, 1.07897059, 1.07897059, 0.97097297,\n",
              "       1.07897059, 0.97097297, 1.07897059, 1.19178571, 0.97097297,\n",
              "       0.97097297, 0.97097297, 1.07897059, 1.07897059, 1.19178571,\n",
              "       1.19178571, 0.97097297, 0.97097297, 0.97097297, 0.97097297,\n",
              "       1.19178571, 0.97097297, 1.07897059, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.97097297, 0.97097297, 0.71736842,\n",
              "       0.97097297, 0.97097297, 1.19178571, 1.07897059, 0.97097297,\n",
              "       1.07897059, 1.07897059, 0.97097297, 1.07897059, 1.19178571,\n",
              "       0.97097297, 1.07897059, 0.97097297, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.97097297, 0.71736842, 1.07897059,\n",
              "       0.71736842, 0.97097297, 0.71736842, 0.97097297, 1.19178571,\n",
              "       0.97097297, 0.97097297, 0.97097297, 0.97097297, 0.97097297,\n",
              "       1.19178571, 1.07897059, 0.97097297, 0.71736842, 0.97097297,\n",
              "       0.97097297, 1.07897059, 1.19178571, 0.97097297, 0.97097297,\n",
              "       1.19178571, 0.97097297, 1.07897059, 0.97097297, 0.97097297,\n",
              "       0.97097297, 1.07897059, 1.07897059, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 1.07897059, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.97097297, 0.97097297, 0.97097297,\n",
              "       1.07897059, 0.97097297, 1.07897059, 0.71736842, 0.71736842,\n",
              "       1.19178571, 0.97097297, 0.97097297, 0.97097297, 0.97097297,\n",
              "       1.07897059, 0.97097297, 0.97097297, 1.19178571, 0.97097297,\n",
              "       1.07897059, 0.71736842, 0.97097297, 0.97097297, 1.07897059,\n",
              "       1.07897059, 1.07897059, 0.97097297, 0.97097297, 1.07897059,\n",
              "       0.71736842, 1.07897059, 0.97097297, 0.97097297, 0.97097297,\n",
              "       1.07897059, 1.07897059, 0.97097297, 0.71736842, 0.97097297,\n",
              "       1.07897059, 1.07897059, 0.97097297, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 1.19178571, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.97097297, 0.97097297, 1.19178571,\n",
              "       0.97097297, 0.97097297, 1.19178571, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.97097297, 1.07897059, 0.97097297,\n",
              "       0.97097297, 0.97097297, 0.97097297, 1.07897059, 0.71736842,\n",
              "       0.97097297, 0.97097297, 1.19178571, 0.97097297, 0.97097297,\n",
              "       0.97097297, 1.19178571, 0.97097297, 0.97097297, 1.07897059,\n",
              "       1.19178571, 0.97097297, 0.97097297, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 1.07897059, 0.71736842, 0.71736842,\n",
              "       0.97097297, 1.19178571, 1.19178571, 1.19178571, 1.19178571,\n",
              "       1.07897059, 0.97097297, 0.97097297, 0.97097297, 0.97097297,\n",
              "       0.97097297, 0.97097297, 1.07897059, 0.97097297, 1.19178571,\n",
              "       1.07897059, 1.19178571, 0.97097297, 1.07897059, 0.97097297,\n",
              "       1.19178571, 0.71736842, 0.97097297, 0.97097297, 0.97097297,\n",
              "       0.97097297, 1.07897059, 0.97097297, 0.97097297, 0.97097297,\n",
              "       0.71736842, 0.97097297, 0.97097297, 0.97097297, 0.97097297,\n",
              "       1.07897059, 0.97097297, 1.19178571, 1.07897059, 0.97097297,\n",
              "       1.19178571, 1.07897059, 1.07897059, 0.97097297, 0.97097297,\n",
              "       0.97097297, 1.07897059, 1.07897059, 0.97097297, 1.19178571,\n",
              "       0.97097297, 0.97097297, 0.97097297, 0.71736842, 1.07897059,\n",
              "       1.19178571, 1.07897059, 1.19178571, 0.97097297, 1.07897059,\n",
              "       0.97097297, 0.97097297, 1.07897059, 0.97097297, 0.97097297,\n",
              "       0.97097297, 1.07897059, 1.07897059, 1.07897059, 0.97097297,\n",
              "       1.07897059, 1.07897059, 1.07897059, 0.97097297, 1.07897059,\n",
              "       0.97097297, 0.97097297, 1.07897059, 0.97097297, 0.97097297,\n",
              "       0.97097297, 1.07897059, 0.97097297, 0.97097297, 0.97097297,\n",
              "       0.97097297, 1.07897059, 0.97097297, 1.07897059, 0.97097297])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3pXwJ_AQimK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10123c64-1a90-47c7-e249-789928d34857"
      },
      "source": [
        "# Train a model using weights\n",
        "best_lr_weights, _, _, _ = tune_logistic_regression(train_orig_df.drop('age', axis=1), val_orig_df.drop('age', axis=1),\n",
        "                                                                       penalty_types=[\"l1\", \"l2\"], C_values=[0.001, 0.1, 1, 10, 100, 1000, 10000, 100000], \n",
        "                                                                       weights=training_weights, verbose=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Best model parameters:  {'penalty': 'l2', 'C': 0.1}\n",
            "Best model AUC:  0.775209340724142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvcEwpwPQimL"
      },
      "source": [
        "Hey look-- our AUC fell again. As we've discussed, there's often a tradeoff between fairness and other metrics that stakeholders care about. \n",
        "\n",
        "Let's see if the fairness metrics changed. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ej_9ovOQimL"
      },
      "source": [
        "train_preds_df_weights = train_orig_df.copy()\n",
        "train_preds_df_weights['credit'] = best_lr_weights.predict(x_train.drop('age', axis=1))\n",
        "train_preds_df_weights['credit'] = train_preds_df_weights.credit.replace({0:2})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQi9TyYNQimL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a973e0b7-e8dc-4ca8-a5b9-a9728eb29ffc"
      },
      "source": [
        "preds_weights_aif360 = StandardDataset(train_preds_df_weights, label_name='credit', protected_attribute_names=['age'], \n",
        "                privileged_classes=[[1]], favorable_classes=[1])\n",
        "preds_weights_metrics = BinaryLabelDatasetMetric(preds_weights_aif360, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "print(\"Mean difference = %f\" % preds_weights_metrics.mean_difference())\n",
        "print(\"Disparate Impact = %f\" % preds_weights_metrics.disparate_impact())\n",
        "\n",
        "orig_vs_preds_weights_metrics = ClassificationMetric(orig_aif360, preds_weights_aif360,\n",
        "                                                   unprivileged_groups=unprivileged_groups,\n",
        "                                                   privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"\\nError rate difference (unprivileged error rate - privileged error rate)= %f\" % orig_vs_preds_weights_metrics.error_rate_difference())\n",
        "\n",
        "print(\"\\nFalse negative rate for privledged groups = %f\" % orig_vs_preds_weights_metrics.false_negative_rate(privileged=True))\n",
        "print(\"False negative rate for unprivledged groups = %f\" % orig_vs_preds_weights_metrics.false_negative_rate(privileged=False))\n",
        "print(\"False negative rate ratio = %f\" % orig_vs_preds_weights_metrics.false_negative_rate_ratio())\n",
        "\n",
        "\n",
        "print(\"\\nFalse positive rate for privledged groups = %f\" % orig_vs_preds_weights_metrics.false_positive_rate(privileged=True))\n",
        "print(\"False positive rate for unprivledged groups = %f\" % orig_vs_preds_weights_metrics.false_positive_rate(privileged=False))\n",
        "print(\"False positive rate ratio = %f\" % orig_vs_preds_weights_metrics.false_positive_rate_ratio())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean difference = -0.079892\n",
            "Disparate Impact = 0.905548\n",
            "\n",
            "Error rate difference (unprivileged error rate - privileged error rate)= 0.067110\n",
            "\n",
            "False negative rate for privledged groups = 0.064865\n",
            "False negative rate for unprivledged groups = 0.089286\n",
            "False negative rate ratio = 1.376488\n",
            "\n",
            "False positive rate for privledged groups = 0.602941\n",
            "False positive rate for unprivledged groups = 0.552632\n",
            "False positive rate ratio = 0.916560\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE9Fq1HXQimM"
      },
      "source": [
        "How do these numbers compare to the numbers above?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9ghCQm7pUUo"
      },
      "source": [
        "**These numbers appear to be far less bias than simply filtering out age. Both the false positive and negative rate ratios are close to one, indicating an almost even false prediction rate among unprivileged and privileged groups. Even the the mean difference has gone down and the disparate impact has moved far closer to one, indicating less bias in the amount of favorable outcomes between privileged and unprivileged groups.** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7316kh6-QimM"
      },
      "source": [
        "## Step 5: Post-process the predictions from the model that we trained using weights by using the calibrated equality of odds algorithm \n",
        "\n",
        "The equality of odds algorithm is a method for adjusting predicted probabilities to ensure that the false negative rate is equal for the privilged and unprivilged groups. (This also ensures that the true positive rate is equal.) To do so, the algorithm uses the predicted probabilities and determines *two* threshold probabilitties for each group. Above the upper threshold, all members of the group are assigned to the positive class, and below the lower threshold, all members of the group are assigned to the negative class. But between the two thresholds, individuals are randomly assigned a class. \n",
        "\n",
        "For details, see M. Hardt, E. Price, and N. Srebro, “Equality of Opportunity in Supervised Learning,” Conference on Neural Information Processing Systems, 2016.\n",
        "\n",
        "Which definitions of fairness does this post-processing algorithm contradict?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5aLfsvnQimN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a36534e-c6a5-4a38-e483-2a71bd6fabdb"
      },
      "source": [
        "# Transform our predictions using the aif360 implementation of the equality of odds algorithm\n",
        "eq_odds = EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=47)\n",
        "preds_weights_eq_odds_aif360 = eq_odds.fit_predict(orig_aif360, preds_weights_aif360)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:87: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah9hMQguEcmM"
      },
      "source": [
        "Again, calculate fairness metrics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_jogmsyQimN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87446de7-788a-4140-d453-99ec919b12a6"
      },
      "source": [
        "# write code to calculate fairness metrics here (see end of step 4, above)\n",
        "preds_weights_eq_odds_metrics = BinaryLabelDatasetMetric(\n",
        "     preds_weights_eq_odds_aif360, \n",
        "     unprivileged_groups = unprivileged_groups,\n",
        "     privileged_groups = privileged_groups\n",
        "  )\n",
        "\n",
        "orig_vs_preds_weights_eq_odds_metrics = ClassificationMetric(\n",
        "     orig_aif360, preds_weights_eq_odds_aif360,\n",
        "     unprivileged_groups = unprivileged_groups,\n",
        "     privileged_groups = privileged_groups\n",
        "  )\n",
        "\n",
        "\n",
        "# print the metrics\n",
        "print(\"Mean difference = %f\" % preds_weights_eq_odds_metrics.mean_difference())\n",
        "print(\"Disparate Impact = %f\" % preds_weights_eq_odds_metrics.disparate_impact())\n",
        "\n",
        "print(\"\\nError rate difference (unprivileged error rate - privileged error rate)= %f\" % orig_vs_preds_weights_eq_odds_metrics.error_rate_difference())\n",
        "\n",
        "print(\"\\nFalse negative rate for privledged groups = %f\" % orig_vs_preds_weights_eq_odds_metrics.false_negative_rate(privileged=True))\n",
        "print(\"False negative rate for unprivledged groups = %f\" % orig_vs_preds_weights_eq_odds_metrics.false_negative_rate(privileged=False))\n",
        "print(\"False negative rate ratio = %f\" % orig_vs_preds_weights_eq_odds_metrics.false_negative_rate_ratio())\n",
        "\n",
        "\n",
        "print(\"\\nFalse positive rate for privledged groups = %f\" % orig_vs_preds_weights_eq_odds_metrics.false_positive_rate(privileged=True))\n",
        "print(\"False positive rate for unprivledged groups = %f\" % orig_vs_preds_weights_eq_odds_metrics.false_positive_rate(privileged=False))\n",
        "print(\"False positive rate ratio = %f\" % orig_vs_preds_weights_eq_odds_metrics.false_positive_rate_ratio())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean difference = 0.008662\n",
            "Disparate Impact = 5.382979\n",
            "\n",
            "Error rate difference (unprivileged error rate - privileged error rate)= -0.126819\n",
            "\n",
            "False negative rate for privledged groups = 1.000000\n",
            "False negative rate for unprivledged groups = 1.000000\n",
            "False negative rate ratio = 1.000000\n",
            "\n",
            "False positive rate for privledged groups = 0.007353\n",
            "False positive rate for unprivledged groups = 0.026316\n",
            "False positive rate ratio = 3.578947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTz1Iq2iQimO"
      },
      "source": [
        "What's changed in these metrics? How could the algorithm have caused that? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP-8BAK8QimO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22aec8aa-b3aa-46bb-8650-7efde785cb2a"
      },
      "source": [
        "# Test how accuracy has changed\n",
        "print(\"\\nAccuracy (on training data) before equality of odds algorithm = %f\" % orig_vs_preds_weights_metrics.accuracy())\n",
        "print(\"\\nAccuracy (on training data) after equality of odds algorithm = %f\" % orig_vs_preds_weights_eq_odds_metrics.accuracy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy (on training data) before equality of odds algorithm = 0.780000\n",
            "\n",
            "Accuracy (on training data) after equality of odds algorithm = 0.286667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmtPedyUE3Pi"
      },
      "source": [
        "**Write your answer in this text cell:** The mean difference dropped to an almost insignificant level indicating a more fair favorable outcome distribution, disparate impact is >1 indicating that the unprivileged group recieved far more favorable outcomes to the privileged group, the false negative rate ratio indicates an even false negative rate between the two groups, and the rather high false positive rate still indicates a probable bias against the unprivileged group. After the equality of odds algorithm was included, the accuracy of the training data obviously went down because the training data does not necessarily reflect the original data/ realistic data."
      ]
    }
  ]
}